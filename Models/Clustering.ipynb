{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-08T13:36:00.725390Z",
     "start_time": "2020-04-08T13:36:00.700402Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# in clusters we only have 1 dataset as it is unsupervised learning so no y dataframe \n",
    "#X_train= #the training data \n",
    "clf = AgglomerativeClustering(n_clusters= 2 , linkage= 'ward') \n",
    "# for linkage you hace ward , single , average , complete clustrering methods , each differs in how to calculate variance\n",
    "# n_cluster for the number of clusters you want, linkage is the type of algorithm to calculate the distance between clusters \n",
    "clf.fit(X_train)\n",
    "y_predict=clf.fit_predict(X_test)\n",
    "\n",
    "\n",
    "# another way to make hierarchical clustrering but with visualizations\n",
    "from scipy.cluster.hierarchy import dendrogram, ward \n",
    "import matplotlib as plt\n",
    "clf = ward(X_train)\n",
    "dendrogram(link_type) # to plot the dendrogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans_model= KMeans(n_clusters=2)\n",
    "kmeans_model.fit(X_test)\n",
    "y_predict = kmeans_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "meanshift_model = MeanShift(n_jobs=-1)\n",
    "meanshift_model.fit(X)\n",
    "# %%from sklearn.metrics import classification_report\n",
    "y_predict = kmeans_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db_model = DBSCAN(  eps= 0.05 , min_samples= 10  ) # use grid search to find the best value for eps and min_samples\n",
    "db_model.fit( X_train )\n",
    "y_predict = db_model.predict( X_test )\n",
    "\n",
    "# use db_model.labels_ to view the cluster of each data point , where -1 referes to noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm=GaussianMixture( n_components= 2 ) #n_components is the number of clusters \n",
    "gmm.fit(X_train)\n",
    "y_predict=gmm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to validate clustering based algorithms\n",
    "use clustering validation methods, and for dbscan use dbcv method as it tends to ignore the noise from the data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
